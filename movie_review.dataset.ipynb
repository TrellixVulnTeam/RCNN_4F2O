{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": true
   },
   "level": 1,
   "source": [
    "Investigate implementation of the Movie Reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import torchtext.data as data\n",
    "\n",
    "from src import movie_reviews_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train) 8530\nlen(dev) 2132\n['about', 'as', 'original', 'as', 'a', 'gangster', 'sweating', 'bullets', 'while', 'worrying', 'about', 'a', 'contract', 'on', 'his', 'life', '']\n"
     ]
    }
   ],
   "source": [
    "text_field = data.Field(lower=True)\n",
    "label_field = data.Field(sequential=False)\n",
    "\n",
    "print('loading dataset')\n",
    "train_data, dev_data = movie_reviews_dataset.MR.splits(text_field, label_field, root='./data', dev_ratio=.2)\n",
    "\n",
    "print('len(train)', len(train_data))\n",
    "print('len(dev)', len(dev_data))\n",
    "\n",
    "print(train_data.examples[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_field.vocab.size 21109\nlabel_field.vocab.size 3\n"
     ]
    }
   ],
   "source": [
    "text_field.build_vocab(train_data, dev_data)\n",
    "label_field.build_vocab(train_data, dev_data)\n",
    "\n",
    "print('text_field.vocab.size', len(text_field.vocab))\n",
    "print('label_field.vocab.size', len(label_field.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, dev_iter = data.Iterator.splits((train_data, dev_data), \n",
    "                                            batch_sizes=(4, len(dev_data)), device=-1, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['this', 'rough', 'trade', 'punch and judy', 'act', \"did n't\", 'play', 'well', 'then', 'and', 'it', 'plays', 'worse', 'now', '', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n1 ['the', 'film', 'starts', 'promisingly', ',', 'but', 'the', 'ending', 'is', 'all', 'too', 'predictable', 'and', 'far', 'too', 'cliched', 'to', 'really', 'work', '', '<pad>', '<pad>']\n2 ['a', 'compassionate', ',', 'moving', 'portrait', 'of', 'an', 'american', '\\\\(', 'and', 'an', 'america', '\\\\)', 'always', 'reaching', 'for', 'something', 'just', 'outside', 'his', 'grasp', '']\n3 ['while', 'super', 'troopers', 'is', 'above', 'academy', 'standards', ',', 'its', 'quintet', 'of', 'writers', 'could', 'still', 'use', 'some', 'more', 'schooling', '', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "batch.text.data.t_()\n",
    "\n",
    "for i in range(4):\n",
    "    sample = batch.text.data[i, :]\n",
    "    print(i, [text_field.vocab.itos[num] for num in sample])"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Use embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding input dims:  torch.Size([4, 28])\nEmbedding dims:  torch.Size([4, 28, 300])\nRepeated embeddings of the same data should be the same:  True\n"
     ]
    }
   ],
   "source": [
    "embed = torch.nn.Embedding(num_embeddings=len(text_field.vocab), embedding_dim=300)\n",
    "print('Embedding input dims: ', batch.text.data.size())\n",
    "embedded = embed(batch.text)\n",
    "print('Embedding dims: ', embedded.size())\n",
    "print('Repeated embeddings of the same data should be the same: ', \n",
    "      np.array_equal(embedded.data.numpy(), embed(batch.text).data.numpy()))"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 3,
   "source": [
    "Use embeddings with GloVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors from .data_cache/glove.6B.300d.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized GloVE embeddings with dim:  torch.Size([21109, 300])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding w/ GloVE dims:  torch.Size([4, 28, 300])\nRepeated embeddings of the same data should be the same:  True\nEmbedded tensors should be different between GloVE and un-initialized embeddings:  True\nReturned embedded value is the same between input embedding tensor and output of the Embedder True\n"
     ]
    }
   ],
   "source": [
    "text_field.vocab.load_vectors(wv_dir='.data_cache', wv_type='glove.6B', wv_dim=300)\n",
    "print('Initialized GloVE embeddings with dim: ', text_field.vocab.vectors.size())\n",
    "embed_glove = torch.nn.Embedding(num_embeddings=len(text_field.vocab), embedding_dim=300)\n",
    "del embed_glove.weight\n",
    "embed_glove.weight = torch.nn.Parameter(text_field.vocab.vectors)\n",
    "\n",
    "embedded_glove = embed_glove(batch.text)\n",
    "print('Embedding w/ GloVE dims: ', embedded_glove.size())\n",
    "print('Repeated embeddings of the same data should be the same: ', \n",
    "      np.array_equal(embedded_glove.data.numpy(), embed_glove(batch.text).data.numpy()))\n",
    "\n",
    "print('Embedded tensors should be different between GloVE and un-initialized embeddings: ', \n",
    "      not np.array_equal(embedded_glove.data.numpy(), embedded.data.numpy()))\n",
    "\n",
    "print('Returned embedded value is the same between input embedding tensor and output of the Embedder', \n",
    "      np.array_equal(embedded_glove.data[0, 0].numpy(), text_field.vocab.vectors[batch.text.data[0, 0]].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}